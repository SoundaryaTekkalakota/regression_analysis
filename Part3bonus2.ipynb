{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "fpath = './insurance_data.csv'\n",
    "import numpy as np\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import cross_validate\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import plotly as py\n",
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "py.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ft1     ft2  ft3     ft4  ft5        ft6      charges\n",
      "0   19  27.900    0  female  yes  southwest  16884.92400\n",
      "1   18  33.770    1    male   no  southeast   1725.55230\n",
      "2   28  33.000    3    male   no  southeast   4449.46200\n",
      "3   33  22.705    0    male   no  northwest  21984.47061\n",
      "4   32  28.880    0    male   no  northwest   3866.85520\n",
      "(1338, 6)\n",
      "(1338, 13)\n"
     ]
    }
   ],
   "source": [
    "data_orig = pd.read_csv(fpath)\n",
    "data = data_orig\n",
    "\n",
    "#0 => Female; 1=> Male\n",
    "data['ft4'] = data['ft4'].astype('category').cat.codes\n",
    "\n",
    "#0 => No; 1=> Yes\n",
    "data['ft5'] = data['ft5'].astype('category').cat.codes\n",
    "\n",
    "#0 => NE; 1=> NW; 2=> SE; 3=> SW\n",
    "data['ft6'] = data['ft6'].astype('category').cat.codes\n",
    "\n",
    "data['ft7'] = data['ft2']*data['ft5']\n",
    "Xs = data.iloc[:,:6].values\n",
    "print(Xs.shape)\n",
    "Xs = np.append(Xs,(Xs[:,1]*Xs[:,4]).reshape((Xs.shape[0],1)), axis=1)\n",
    "for i in [0,1]:\n",
    "    for j in [2,3,4]:\n",
    "        Xs = np.append(Xs,(Xs[:,i]**j).reshape((Xs.shape[0],1)), axis=1)\n",
    "ys = data.iloc[:,6].values\n",
    "print(Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import SCORERS\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def randomForest(model, X, y):\n",
    "    kf = KFold(n_splits=10)\n",
    "    rmse_train, rmse_test, oob_error = 0, 0, 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        model.fit(X_train, y_train)\n",
    "        rmse_train += sqrt(mean_squared_error(y_train, model.predict(X_train)))\n",
    "        rmse_test += sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "        oob_error += 1 - model.oob_score_\n",
    "    return rmse_train / 10, rmse_test / 10, oob_error/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:37<00:00,  6.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "rmse_train_arr, rmse_test_arr, oob_arr = [],[],[]\n",
    "max_depth = 4\n",
    "trees = list(range(5,200,5))\n",
    "trees = [600]\n",
    "for num_feat in tqdm(range(1,7)):\n",
    "    rmse_train_arr.append([])\n",
    "    rmse_test_arr.append([])\n",
    "    oob_arr.append([])\n",
    "    for num_trees in trees:\n",
    "        RF = RandomForestRegressor(n_estimators = num_trees, max_depth = max_depth, max_features = num_feat, bootstrap = True, oob_score=True)\n",
    "        a, b, c = randomForest(RF,Xs,ys)\n",
    "        rmse_train_arr[num_feat-1].append(a)\n",
    "        rmse_test_arr[num_feat-1].append(b)\n",
    "        oob_arr[num_feat-1].append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "X = X.drop(['charges'], axis=1)\n",
    "\n",
    "X.loc[X['ft4'] == 'male', 'ft4'] = 0\n",
    "X.loc[X['ft4'] == 'female', 'ft4'] = 1\n",
    "\n",
    "X.loc[X['ft5'] == 'no', 'ft5'] = 0\n",
    "X.loc[X['ft5'] == 'yes', 'ft5'] = 1\n",
    "\n",
    "X.loc[X['ft6'] == 'southwest', 'ft6'] = 0\n",
    "X.loc[X['ft6'] == 'southeast', 'ft6'] = 1\n",
    "X.loc[X['ft6'] == 'northwest', 'ft6'] = 2\n",
    "X.loc[X['ft6'] == 'northeast', 'ft6'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3999.055078308132\n"
     ]
    }
   ],
   "source": [
    "best_depth = 6\n",
    "best_num_trees = 200\n",
    "best_feat = 7\n",
    "#for best_depth in range(4,8):\n",
    "best_RF = RandomForestRegressor(n_estimators = best_num_trees, max_depth = best_depth,  min_samples_split=10,\n",
    "                                 random_state=0, bootstrap = True, oob_score=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ys, test_size=0.1, random_state=0)\n",
    "best_RF.fit(X_train, y_train)\n",
    "y_pred = best_RF.predict(X_test)\n",
    "print(sqrt(mse(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 168 candidates, totalling 840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 840 out of 840 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20915.617373012563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "\n",
    "params = {'hidden_layer_sizes': [(60, 20), (50, 20), \n",
    "                                 (60, 30), (50, 30),\n",
    "                                 (60, 40), (60, 40)],\n",
    "          'learning_rate_init': [1e-5, 1e-6, 1e-7, 1e-8], \n",
    "          'alpha': [0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4]}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ys, test_size=0.1, random_state=0)\n",
    "nn = MLPRegressor(activation='relu')\n",
    "clf = GridSearchCV(nn, params, n_jobs=-1, cv=5, verbose = True)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "#X_train_scaled = np.load('X_train')\n",
    "#X_test_scaled = np.load('X_test','rb')\n",
    "clf = clf.fit(X_train_scaled, y_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "print(sqrt(mse(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   37.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3710.376993517298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "params={'n_estimators':list(range(1000,1500,50)),\n",
    "          'learning_rate':[1e-8, 1e-6, 1e-5,1e-4,1e-2] }\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ys, train_size=0.9)\n",
    "gs = GridSearchCV(gb, params, n_jobs=-1, cv=5, verbose=True)\n",
    "gs.fit(X_train, y_train)\n",
    "y_pred = gs.predict(X_test)\n",
    "print(sqrt(mse(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.001, loss='ls', max_depth=3,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=1450,\n",
      "             n_iter_no_change=None, presort='auto', random_state=42,\n",
      "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
